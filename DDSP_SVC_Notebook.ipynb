{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StruckX/struck-notebooks/blob/main/DDSP_SVC_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1ZRVbTR_1go"
      },
      "source": [
        "# DDSP-SVC Notebook\n",
        "Made by Struck | [DDSP-SVC GitHub](https://github.com/yxlllc/DDSP-SVC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXrnfmRWJ7JV"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "rPF6IO-JZgsS"
      },
      "outputs": [],
      "source": [
        "#@markdown ## Check Device\n",
        "#@markdown Check if you're using a gpu.\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "x4Rx7yqbACwl"
      },
      "outputs": [],
      "source": [
        "#@markdown ## Mount Drive\n",
        "#@markdown If you want to save your stuffs to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BMkybqlfAJcQ"
      },
      "outputs": [],
      "source": [
        "#@markdown ## Install DDSP-SVC\n",
        "#@markdown Clone the repo and install dependencies\n",
        "\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "\n",
        "!git clone https://github.com/yxlllc/DDSP-SVC\n",
        "\n",
        "%cd /content/DDSP-SVC\n",
        "\n",
        "!pip install --upgrade pip setuptools numpy numba\n",
        "!pip install pyworld praat-parselmouth torchcrepe einops local_attention wave fairseq transformers tensorboardX\n",
        "\n",
        "clear_output()\n",
        "\n",
        "print(\"Done! Restrating runtime...\");\n",
        "\n",
        "!sleep 3; kill {os.getpid()}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ## Install Encoder\n",
        "#@markdown Select what encoder to use\n",
        "\n",
        "encoder = \"contentvec768l12\" #@param [\"hubertsoft\", \"contentvec\", \"contentvec768\", \"contentvec768l12\"]\n",
        "\n",
        "%cd /content/DDSP-SVC\n",
        "\n",
        "!rm -rf \"pretrain/hubert\" \"pretrain/ContentVec\"\n",
        "\n",
        "if encoder == \"hubertsoft\":\n",
        "  encoder_ckpt = \"pretrain/hubert/hubert-soft-0d54a1f4.pt\"\n",
        "  enc_out_ch = 256\n",
        "  !mkdir -p \"pretrain/hubert\" &> /dev/null\n",
        "  !wget -nc -q --show-progress -O {encoder_ckpt} \"https://github.com/bshall/hubert/releases/download/v0.1/hubert-soft-0d54a1f4.pt\"\n",
        "elif encoder == \"contentvec\":\n",
        "  encoder_ckpt = \"pretrain/contentvec/checkpoint_best_legacy_500.pt\"\n",
        "  enc_out_ch = 256\n",
        "  !mkdir -p \"pretrain/contentvec\" &> /dev/null\n",
        "  !wget -nc -q --show-progress -O {encoder_ckpt} \"https://github.com/fishaudio/fish-diffusion/releases/download/v1.12/content-vec-best-legacy-500.pt\"\n",
        "else:\n",
        "  encoder_ckpt = \"pretrain/contentvec/checkpoint_best_legacy_500.pt\"\n",
        "  enc_out_ch = 768\n",
        "  !mkdir -p \"pretrain/contentvec\" &> /dev/null\n",
        "  !wget -nc -q --show-progress -O {encoder_ckpt} \"https://github.com/fishaudio/fish-diffusion/releases/download/v1.12/content-vec-best-legacy-500.pt\"\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "surrrqGOvwbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDjmNvtTI1tR"
      },
      "source": [
        "# Training\n",
        "\n",
        "**Disclaimer:** Please make sure to only train DDSP-SVC models with legally obtained authorized data, and do not use these models and any audio they synthesize for illegal purposes. The author of this repository *(and notebook)* is not responsible for any infringement, fraud and other illegal acts caused by the use of these model checkpoints and audio. ([DDSP-SVC README](https://github.com/yxlllc/DDSP-SVC/blob/master/README.md))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bj9orgNoBIYz",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ## Extract Dataset\n",
        "#@markdown Run only if you're making a new model or want to preprocess again.\n",
        "\n",
        "#@markdown All archives that `7z` supports such as `7z`, `zip`, `rar`, etc. can be used.\n",
        "#@markdown <details>\n",
        "#@markdown <summary>Your files inside the archive must look <b>EXACTLY</b> like this (<a>click me!</a>)</summary>\n",
        "#@markdown\n",
        "#@markdown Single Speaker:<br>![Single Speaker](https://cdn.discordapp.com/attachments/1061982906895057009/1103739922885652621/image.png)<br><br>\n",
        "#@markdown Multi-speaker:<br>![Multi-Speaker](https://cdn.discordapp.com/attachments/1061982906895057009/1103749167794364548/image.png)\n",
        "#@markdown </details>\n",
        "\n",
        "%cd /content/DDSP-SVC\n",
        "\n",
        "archive_dir = \"/content/model-dataset.7z\" #@param {type: \"string\"}\n",
        "\n",
        "!rm -r ./data/*\n",
        "!7z x '{archive_dir}' -o\"data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUmOnUucHr6f",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ## Extract Preprocessed Dataset\n",
        "#@markdown Run this instead if you already preprocessed your dataset.\n",
        "archive_dir = \"/content/drive/MyDrive/preprocessed-dataset.7z\" #@param {type: \"string\"}\n",
        "config_dir = \"/content/drive/MyDrive/combsub-sins-etc.yaml\" #@param {type: \"string\"}\n",
        "\n",
        "!rm -r ./data/*\n",
        "!7z x '{archive_dir}' -o\"data\"\n",
        "!cp '{config_dir}' configs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DURHy49bO-6c"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@markdown ## Configurations\n",
        "\n",
        "import yaml\n",
        "\n",
        "#@markdown Model config:\n",
        "model_name = \"model-ai\" #@param {type: \"string\"}\n",
        "\n",
        "synthesizer = \"combsub\" #@param [\"combsub\",\"combsub-old\", \"sins\"]\n",
        "\n",
        "pitch_extractor = \"parselmouth\" #@param [\"parselmouth\",\"dio\",\"harvest\",\"crepe\"]\n",
        "\n",
        "number_of_speaker = 1 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown Save checkpoints to a directory:\n",
        "use_save_dir = False #@param {type: \"boolean\"}\n",
        "save_dir_path = \"exp/model-ai\" #@param {type: \"string\"}\n",
        "\n",
        "with open(f\"configs/{synthesizer}.yaml\", \"r+\") as f:\n",
        "  y = yaml.safe_load(f)\n",
        "  y['data']['f0_extractor'] = pitch_extractor\n",
        "  y['data']['encoder'] = encoder\n",
        "  y['data']['encoder_out_channels'] = enc_out_ch\n",
        "  y['data']['encoder_ckpt'] = encoder_ckpt\n",
        "  y['model']['n_spk'] = number_of_speaker if number_of_speaker > 0 else 1\n",
        "  y['env']['expdir'] = save_dir_path if use_save_dir else f\"exp/{model_name}\"\n",
        "  f.seek(0)\n",
        "  f.write(yaml.dump(y, default_flow_style=False, sort_keys=False))\n",
        "  f.truncate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "G4QeZLv7L2ZP",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ## Start Preprocess\n",
        "#@markdown Skip if you already have a preprocessed data.\n",
        "\n",
        "import os\n",
        "\n",
        "save_to_drive = True #@param {type: \"boolean\"}\n",
        "\n",
        "if not any(files.endswith('.wav') for files in os.listdir(\"data/val/audio\")):\n",
        "  !python draw.py\n",
        "\n",
        "!python preprocess.py -c configs/{synthesizer}.yaml\n",
        "\n",
        "if save_to_drive:\n",
        "  model_drive_path = f'/content/drive/MyDrive/DDSP-SVC/data/{model_name}'\n",
        "  !mkdir -p '{model_drive_path}'\n",
        "  !7z a -mx=1 '{model_drive_path}/preprocessed_dataset.7z' ./data/*\n",
        "  !cp 'configs/{synthesizer}.yaml' '{model_drive_path}'\n",
        "  print(f\"Done! Files saved at {model_drive_path}\")\n",
        "else:\n",
        "  !7z a -mx=1 '/content/{model_name}_data/preprocessed_dataset.7z' ./data/*\n",
        "  !cp 'configs/{synthesizer}.yaml' '/content/{model_name}_data'\n",
        "  print(f\"Done! Files saved at /content/{model_name}_data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYLDYGIiWH8g",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ## Start Tensorboard\n",
        "#@markdown Visualize your model's progress. Note that predicted audios aren't enhanced, only in inference.\n",
        "\n",
        "import IPython\n",
        "\n",
        "%reload_ext tensorboard\n",
        "\n",
        "if use_save_dir:\n",
        "  %tensorboard --logdir '{save_dir_path}'\n",
        "else:\n",
        "  %tensorboard --logdir 'exp/{model_name}'\n",
        "\n",
        "display(IPython.display.HTML('''\n",
        "<button onclick=\"window.open(document.querySelector('iframe').src, '__blank')\">Open in New Tab</button> \n",
        "<button onclick=\"document.querySelector('iframe').style.display = 'none'\">Hide TensorBoard</button>\n",
        "<button onclick=\"document.querySelector('iframe').style.display = 'block'\">Show TensorBoard</button> \n",
        "'''))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tTk1HzY8W-Rj"
      },
      "outputs": [],
      "source": [
        "#@markdown ## Start Training\n",
        "#@markdown Train! Train! Train!\n",
        "\n",
        "!python train.py -c configs/{synthesizer}.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "RX__1JXkh-ig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ## Install Enhancer\n",
        "#@markdown Optional but recommended\n",
        "\n",
        "enhancer = \"OpenVPI\" #@param [\"OpenVPI\", \"fishaudio\"]\n",
        "\n",
        "!rm -r pretrain/nsf_hifigan\n",
        "if enhancer == \"OpenVPI\":\n",
        "  !wget -q --show-progress -O /content/nsf_hifigan.zip \"https://github.com/openvpi/vocoders/releases/download/nsf-hifigan-v1/nsf_hifigan_20221211.zip\"\n",
        "else:\n",
        "  !wget -q --show-progress -O /content/nsf_hifigan.zip \"https://github.com/fishaudio/fish-diffusion/releases/download/v2.0.0/nsf_hifigan-stable-v1.zip\"\n",
        "!7z x /content/nsf_hifigan.zip -o\"pretrain\"\n",
        "!rm /content/nsf_hifigan.zip"
      ],
      "metadata": {
        "cellView": "form",
        "id": "WuHdXuZaicU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ## Voice Conversion\n",
        "\n",
        "#@markdown Main Settings:\n",
        "input_audio = \"/content/drive/input.wav\" #@param {type: \"string\"}\n",
        "\n",
        "model_pt = \"/content/drive/model_0.pt\" #@param {type: \"string\"}\n",
        "\n",
        "output_audio = \"/content/output.flac\" #@param {type: \"string\"}\n",
        "\n",
        "keychange = 0 #@param {type:\"integer\"}\n",
        "\n",
        "pitch_extractor = \"parselmouth\" #@param [\"parselmouth\", \"dio\", \"harvest\", \"crepe\"]\n",
        "\n",
        "#@markdown Speaker Settings:\n",
        "\n",
        "speaker_id = 1 #@param {type:\"integer\"}\n",
        "\n",
        "mix_speaker = False #@param {type: \"boolean\"}\n",
        "\n",
        "mix_ratio = \"1:0.50, 2:0.50\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown Enhancer Settings:\n",
        "\n",
        "use_enhancer = True #@param {type: \"boolean\"}\n",
        "\n",
        "enhancer_adaptive_key = 0 #@param {type:\"integer\"}\n",
        "\n",
        "infer_flags = f'''\\\n",
        "-i \"{input_audio}\" \\\n",
        "-m \"{model_pt}\" \\\n",
        "-o \"{output_audio}\" \\\n",
        "-k {keychange} \\\n",
        "-pe {pitch_extractor} \\\n",
        "{f\"-mix '{{{mix_ratio}}}'\" if mix_speaker else f\"-id {speaker_id}\"} \\\n",
        "{f\"-eak {enhancer_adaptive_key}\" if use_enhancer else \"-e false\"}\n",
        "'''\n",
        "\n",
        "!python main.py {infer_flags}"
      ],
      "metadata": {
        "id": "xhnqgPaYvvAU",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ## Download Output\n",
        "\n",
        "from IPython.display import display, Audio\n",
        "\n",
        "preview_only = True #@param {type:\"boolean\"}\n",
        "\n",
        "if preview_only:\n",
        "  audio = open(output_audio, \"rb\").read()\n",
        "  display(Audio(audio))\n",
        "else:\n",
        "  from google.colab import files\n",
        "  files.download(output_audio)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "gYb89c0lSVhn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}